{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6f89086",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Aayush\n",
      "[nltk_data]     Rehal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Aayush\n",
      "[nltk_data]     Rehal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Aayush\n",
      "[nltk_data]     Rehal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import required libraries\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "import os\n",
    "\n",
    "# Ensure the necessary NLTK data files are downloaded\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "app = FastAPI()\n",
    "# Define the corpus\n",
    "corpus = \"\"\"Hi there! Can you help me understand the concept of black holes?\n",
    "\n",
    "Absolutely! A black hole is a region in space where the gravitational pull is so strong that not even light can escape from it. This happens when a massive star collapses under its own gravity, compressing all its mass into a very small volume. The boundary around a black hole beyond which nothing can escape is called the event horizon.\n",
    "\n",
    "That's fascinating! What happens if someone falls into a black hole?\n",
    "\n",
    "If someone were to fall into a black hole, they would experience a process called \"spaghettification.\" As they approach the black hole, the gravitational pull would become stronger on their feet than on their head, stretching them out lengthwise. Eventually, they would be pulled apart. However, from the perspective of an outside observer, they would appear to slow down and fade away as they approach the event horizon, never actually seeming to cross it.\n",
    "\n",
    "Wow, that's intense! Can black holes be detected directly?\n",
    "\n",
    "Not directly, because they emit no light. However, we can detect them indirectly by observing their effects on nearby stars and gas. For example, if a star orbits a seemingly empty region of space, the presence of a black hole can be inferred. Additionally, black holes can sometimes emit powerful jets of radiation when they consume nearby matter, which can also be detected.\n",
    "\n",
    "I've heard about supermassive black holes. How are they different from regular black holes?\n",
    "\n",
    "Supermassive black holes are much larger than regular black holes, with masses ranging from millions to billions of times that of our Sun. They are typically found at the centers of galaxies, including our own Milky Way. Their formation is still a topic of research, but they may form through the merging of smaller black holes and the accumulation of vast amounts of matter over time.\n",
    "\n",
    "That's so interesting! Is there any way to escape a black hole once youâ€™re inside?\n",
    "\n",
    "Unfortunately, once you cross the event horizon of a black hole, escape is impossible due to the immense gravitational pull. Even light cannot escape, which is why black holes are \"black.\" The escape velocity inside the event horizon exceeds the speed of light, making it the ultimate point of no return.\n",
    "\n",
    "Thanks for the explanation! Can you recommend a good book or movie about black holes?\n",
    "\n",
    "Sure! For books, you might enjoy \"A Brief History of Time\" by Stephen Hawking, which covers black holes among other fascinating topics in cosmology. For movies, \"Interstellar\" is a great choice. It features a lot of scientifically accurate depictions of black holes, thanks to the input from physicist Kip Thorne.\n",
    "\n",
    "Great, I'll check those out. Thanks for your help!\n",
    "\n",
    "You're welcome! If you have any more questions about black holes or anything else, feel free to ask. Enjoy your reading and movie watching!\n",
    "\"\"\"\n",
    "# Preprocess the text\n",
    "\n",
    "def preprocess(text):\n",
    "            # Tokenize, remove stop words, and lemmatize\n",
    "            return [lemmatizer.lemmatize(word) for word in text.lower().split() if word not in stop_words]\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation)\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def clean(doc):\n",
    "    \"\"\"\n",
    "    Clean and preprocess a document.\n",
    "\n",
    "    Args:\n",
    "        doc (str): The document to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned and preprocessed document.\n",
    "\n",
    "    \"\"\"\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = \"\".join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized\n",
    "\n",
    "# Split the corpus into individual statements\n",
    "statements = corpus.split('\\n\\n')\n",
    "clean_corpus = [clean(statement).split() for statement in statements]\n",
    "\n",
    "# Create a dictionary and document-term matrix\n",
    "dictionary = corpora.Dictionary(clean_corpus)\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in clean_corpus]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a327245",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TextRequest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfastapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPException\n\u001b[0;32m      3\u001b[0m \u001b[38;5;129m@app\u001b[39m\u001b[38;5;241m.\u001b[39mpost(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/predict/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_topic\u001b[39m(text_request: \u001b[43mTextRequest\u001b[49m):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      6\u001b[0m         lemmatizer \u001b[38;5;241m=\u001b[39m WordNetLemmatizer()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TextRequest' is not defined"
     ]
    }
   ],
   "source": [
    "from fastapi import HTTPException\n",
    "\n",
    "@app.post(\"/predict/\")\n",
    "async def predict_topic(text_request: TextRequest):\n",
    "    try:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        \n",
    "        def preprocess(text):\n",
    "            # Tokenize, remove stop words, and lemmatize\n",
    "            return [lemmatizer.lemmatize(word) for word in text.lower().split() if word not in stop_words]\n",
    "\n",
    "        text_data = text_request.text\n",
    "        processed_text = preprocess(text_data)\n",
    "        dictionary = corpora.Dictionary([processed_text])\n",
    "        doc_term_matrix = [dictionary.doc2bow(processed_text)]\n",
    "        \n",
    "        lda_model = LdaModel(doc_term_matrix, num_topics=text_request.num_topics, id2word=dictionary, passes=50)\n",
    "        topics = lda_model.print_topics(num_topics=text_request.num_topics, num_words=text_request.num_words)\n",
    "        \n",
    "        topics_dict = {i: topic for i, topic in topics}\n",
    "        return topics_dict\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=\"An error occurred while processing the request\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    nest_asyncio.apply()\n",
    "    uvicorn.run(app, host=\"127.0.0.1\", port=8001)  # Change the port number if necessary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f122a8",
   "metadata": {},
   "source": [
    "Focus: LSI focuses on relationships between words, LDA focuses on uncovering hidden topics.\n",
    "Method: LSI uses math to find patterns, LDA uses probability to figure out topics.\n",
    "Results: LSI helps find similar documents, LDA helps understand document content."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
